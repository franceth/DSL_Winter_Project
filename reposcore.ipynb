{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics.pairwise import paired_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import csv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics._scorer import make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_func(ground_truth, predictions):\n",
    "     return np.sum(paired_distances(ground_truth, predictions))/len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('development.csv', sep=',')\n",
    "y = df[['x','y']].values\n",
    "df.drop(columns=['x','y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA #132.61\n",
    "pca=PCA()\n",
    "pca_df = pca.fit_transform(df.values)\n",
    "mdf = np.sum(np.cumsum(pca.explained_variance_ratio_) < .90) + 1\n",
    "pca_m = PCA(n_components=mdf)\n",
    "pca_df = pca_m.fit_transform(df.values)\n",
    "X_train = pca_df\n",
    "y_train = y\n",
    "\n",
    "df_eval = pd.read_csv('evaluation.csv', sep=',')\n",
    "eval = df_eval.drop(columns='Id').values\n",
    "\n",
    "pca_df_eval = pca_m.fit_transform(eval)\n",
    "X_valid = pca_df_eval\n",
    "\n",
    "X_train = np.where(np.isinf(X_train), np.finfo(np.float32).max, X_train)\n",
    "reg = RandomForestRegressor(n_estimators = 200, criterion='squared_error', max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "reg.fit(X_train, y_train)   \n",
    "y_pred = reg.predict(X_valid)\n",
    "\n",
    "header = ['Id', 'Predicted']\n",
    "with open(\"submission.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    for i in df_eval['Id']:\n",
    "        writer.writerow([i, ''.join((str(round(y_pred[i, 0],2)), '|', str(round(y_pred[i, 1],2))))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor #183.341\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#std = StandardScaler()\n",
    "#std.fit(X_train)\n",
    "#X_train_norm = std.transform(X_train)\n",
    "#X_valid_norm = std.transform(X_valid)\n",
    "reg = KNeighborsRegressor(n_neighbors=7 , weights='distance')\n",
    "reg.fit(X_train, y_train)                    \n",
    "y_pred = reg.predict(X_valid)\n",
    "header = ['Id', 'Predicted']\n",
    "with open(\"submission.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    for i in df_eval['Id']:\n",
    "        writer.writerow([i, ''.join((str(round(y_pred[i, 0],2)), '|', str(round(y_pred[i, 1],2))))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "noise_pmax = []\n",
    "noise_negpmax = []\n",
    "noise_area = []#4.7\n",
    "noise_tmax = []\n",
    "noise_rms = []\n",
    "noise_vpp = []\n",
    "noise_slewrate = []\n",
    "pmax = [f'pmax[{i}]' for i in range(18)]\n",
    "negpmax = [f'negpmax[{i}]' for i in range(18)]\n",
    "#for i in range(0,18):\n",
    "#    condition = abs(df[f\"tmax[{i}]\"]) > 1e-6\n",
    "#    df[f\"slewrate[{i}]\"] = np.where(condition, ((df[f\"pmax[{i}]\"] - df[f\"negpmax[{i}]\"])) / df[f\"tmax[{i}]\"],  np.finfo(np.float32).max)\n",
    "df = df[df['negpmax[1]'] < 0]\n",
    "df = df[df['negpmax[2]'] < 0]\n",
    "df = df[df['negpmax[3]'] < 0]\n",
    "df = df[df['negpmax[4]'] < 0]\n",
    "df = df[df['negpmax[5]'] < 0]\n",
    "df = df[df['negpmax[6]'] < 0]\n",
    "df = df[df['negpmax[8]'] < 0]\n",
    "df = df[df['negpmax[9]'] < 0]\n",
    "df = df[df['negpmax[10]'] < 0]\n",
    "df = df[df['negpmax[11]'] < 0]\n",
    "df = df[df['negpmax[13]'] < 0]\n",
    "df = df[df['negpmax[14]'] < 0]\n",
    "df = df[df['negpmax[15]'] < 0]\n",
    "#df = df[df[negpmax] < 0]\n",
    "for i in range(0,18):\n",
    "    df[f\"vpp[{i}]\"] = (df[f\"pmax[{i}]\"] - df[f\"negpmax[{i}]\"])\n",
    "#for i in range(0,18):\n",
    "#    df[f\"widh[{i}]\"] = df[f\"area[{i}]\"]/((df[f\"pmax[{i}]\"]-df[f\"negpmax[{i}]\"])/2)\n",
    "#for i in range(0,18):\n",
    "#   df[f\"widhRMS[{i}]\"] = df[f\"rms[{i}]\"]/((df[f\"pmax[{i}]\"]-df[f\"negpmax[{i}]\"])/2)\n",
    "for i in [0, 7, 12, 16, 17]: \n",
    "    noise_pmax.append(f'pmax[{i}]')\n",
    "    noise_area.append(f'area[{i}]')\n",
    "    noise_area.append(f'negpmax[{i}]')\n",
    "    noise_vpp.append(f'vpp[{i}]')\n",
    "    #noise_vpp.append(f'slewrate[{i}]')\n",
    "    #noise_negpmax.append(f'widh[{i}]')\n",
    "    #noise_slewrate.append(f'slewrate[{i}]')\n",
    "    #noise_slewrate.append(f'widh[{i}]')\n",
    "\n",
    "\n",
    "#noise_area.append('area[15]')\n",
    "#noise_area.append('negpmax[15]')\n",
    "\n",
    "for i in range(0, 18): \n",
    "    noise_rms.append(f'rms[{i}]')\n",
    "    noise_tmax.append(f'tmax[{i}]')\n",
    "    #noise_negpmax.append(f'negpmax[{i}]')\n",
    "    #noise_area.append(f'area[{i}]')\n",
    "noise = noise_pmax + noise_negpmax + noise_area + noise_tmax + noise_rms+ noise_vpp + noise_slewrate\n",
    "df.drop(columns=noise, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv('evaluation.csv', sep=',')#4.76 con -neg\n",
    "#for i in range(0,18):\n",
    "#    condition = abs(df_eval[f\"tmax[{i}]\"]) > 1e-6\n",
    "#    df_eval[f\"slewrate[{i}]\"] = np.where(condition, ((df_eval[f\"pmax[{i}]\"] - df_eval[f\"negpmax[{i}]\"])) / df_eval[f\"tmax[{i}]\"], np.finfo(np.float32).max)\n",
    "for i in range(0,18):\n",
    "    df_eval[f\"vpp[{i}]\"] = (df_eval[f\"pmax[{i}]\"] - df_eval[f\"negpmax[{i}]\"])\n",
    "#for i in range(0,18):\n",
    "#    df_eval[f\"widh[{i}]\"] = df_eval[f\"area[{i}]\"]/((df_eval[f\"pmax[{i}]\"]-df_eval[f\"negpmax[{i}]\"])/2)\n",
    "#for i in range(0,18):\n",
    "#    df_eval[f\"widhRMS[{i}]\"] = df_eval[f\"rms[{i}]\"]/((df_eval[f\"pmax[{i}]\"]-df_eval[f\"negpmax[{i}]\"])/2)\n",
    "df_eval.drop(columns=noise, inplace=True)\n",
    "\n",
    "X_train = df.drop(columns=['x', 'y']).values\n",
    "y_trainX = df[['x']].values\n",
    "y_trainY = df[['y']].values\n",
    "y_train = df[['x','y']].values\n",
    "X_test = df_eval.drop(columns='Id').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest con (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.930409975524837\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(n_estimators = 200, criterion='squared_error', max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "reg.fit(X_train, y_train)                    \n",
    "y_pred = reg.predict(X_valid) \n",
    "print(custom_loss_func(y_valid,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest (X) + Random Forest(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.177011414542949\n"
     ]
    }
   ],
   "source": [
    "y_train_x = y_train[:,0]\n",
    "y_train_y = y_train[:,1]\n",
    "#yy = df[['x']].values\n",
    "reg = RandomForestRegressor(n_estimators = 200, criterion='squared_error', max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "reg.fit(X_train, y_train_x)                    \n",
    "y_pred_x = reg.predict(X_valid) \n",
    "reg = RandomForestRegressor(n_estimators = 200, criterion='squared_error', max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "reg.fit(X_train, y_train_y)                    \n",
    "y_pred_y = reg.predict(X_valid)\n",
    "y_pred_y=y_pred_y.reshape(-1,1)\n",
    "y_pred_x = y_pred_x.reshape(-1,1)\n",
    "y_pred= np.hstack((y_pred_x,y_pred_y))\n",
    "print(custom_loss_func(y_valid,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.488862367515643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "X_train_norm = std.transform(X_train)\n",
    "X_valid_norm = std.transform(X_valid)\n",
    "reg = KNeighborsRegressor(n_neighbors=7 , weights='distance')\n",
    "reg.fit(X_train_norm, y_train)                    \n",
    "y_pred = reg.predict(X_valid_norm)\n",
    "print(custom_loss_func(y_valid,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "df = pd.read_csv('development.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_pmax = []\n",
    "noise_negpmax = []\n",
    "noise_area = []#4.7\n",
    "noise_tmax = []\n",
    "noise_rms = []\n",
    "noise_vpp = []\n",
    "noise_slewrate = []\n",
    "pmax = [f'pmax[{i}]' for i in range(18)]\n",
    "negpmax = [f'negpmax[{i}]' for i in range(18)]\n",
    "for i in range(0,18):\n",
    "    df[f\"vpp[{i}]\"] = (df[f\"pmax[{i}]\"] - df[f\"negpmax[{i}]\"])\n",
    "df = df[df['negpmax[1]'] < 0]\n",
    "df = df[df['negpmax[2]'] < 0]\n",
    "df = df[df['negpmax[3]'] < 0]\n",
    "df = df[df['negpmax[4]'] < 0]\n",
    "df = df[df['negpmax[5]'] < 0]\n",
    "df = df[df['negpmax[6]'] < 0]\n",
    "df = df[df['negpmax[8]'] < 0]\n",
    "df = df[df['negpmax[9]'] < 0]\n",
    "df = df[df['negpmax[10]'] < 0]\n",
    "df = df[df['negpmax[11]'] < 0]\n",
    "df = df[df['negpmax[13]'] < 0]\n",
    "df = df[df['negpmax[14]'] < 0]\n",
    "df = df[df['negpmax[15]'] < 0]\n",
    "for i in [0, 7, 12, 16, 17]: \n",
    "    noise_pmax.append(f'pmax[{i}]')\n",
    "    noise_area.append(f'area[{i}]')\n",
    "    noise_area.append(f'negpmax[{i}]')\n",
    "    noise_vpp.append(f'vpp[{i}]')\n",
    "for i in range(0, 18): \n",
    "    noise_rms.append(f'rms[{i}]')\n",
    "    noise_tmax.append(f'tmax[{i}]')\n",
    "noise = noise_pmax + noise_negpmax + noise_area + noise_tmax + noise_rms+ noise_vpp + noise_slewrate\n",
    "df.drop(columns=noise, inplace=True)\n",
    "y = df[['x','y']].values\n",
    "df.drop(columns=['x','y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv('evaluation.csv', sep=',')#4.76 con -neg\n",
    "#for i in range(0,18):\n",
    "#    condition = abs(df_eval[f\"tmax[{i}]\"]) > 1e-6\n",
    "#    df_eval[f\"slewrate[{i}]\"] = np.where(condition, ((df_eval[f\"pmax[{i}]\"] - df_eval[f\"negpmax[{i}]\"])) / df_eval[f\"tmax[{i}]\"], np.finfo(np.float32).max)\n",
    "for i in range(0,18):\n",
    "    df_eval[f\"vpp[{i}]\"] = (df_eval[f\"pmax[{i}]\"] - df_eval[f\"negpmax[{i}]\"])\n",
    "#for i in range(0,18):\n",
    "#    df_eval[f\"widh[{i}]\"] = df_eval[f\"area[{i}]\"]/((df_eval[f\"pmax[{i}]\"]-df_eval[f\"negpmax[{i}]\"])/2)\n",
    "#for i in range(0,18):\n",
    "#    df_eval[f\"widhRMS[{i}]\"] = df_eval[f\"rms[{i}]\"]/((df_eval[f\"pmax[{i}]\"]-df_eval[f\"negpmax[{i}]\"])/2)\n",
    "df_eval.drop(columns=noise, inplace=True)\n",
    "\n",
    "X_train_valid = df.values #df.drop(columns=['x', 'y']).values\n",
    "y_train_valid = y#df[['x','y']].values\n",
    "X_test = df_eval.drop(columns='Id').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.9764732556909985\n",
      "{'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 200, 'n_jobs': -1, 'random_state': 42}\n",
      "Metric value: 3.9121012047690993\n"
     ]
    }
   ],
   "source": [
    "custom_scorer = make_scorer(custom_loss_func, greater_is_better=False)\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "              'criterion': ['squared_error'],\n",
    "              'max_features': ['sqrt', 'log2'],\n",
    "              'random_state': [42],\n",
    "              'n_jobs': [-1]      \n",
    "}\n",
    "#X=df.values\n",
    "#X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42) #stratify=y\n",
    "gs = GridSearchCV(RandomForestRegressor(), param_grid, scoring=custom_scorer, n_jobs=-1, cv=5)\n",
    "gs.fit(X_train_valid, y_train_valid)\n",
    "print(gs.best_score_)   # -4.823035566366996\n",
    "print(gs.best_params_)  # {'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 50, 'n_jobs': -1, 'random_state': 42}\n",
    "y_pred = gs.predict(X_test)\n",
    "#print(f'Metric value: {custom_loss_func(y_test, y_pred)}') # Metric value: 4.742701679372149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric value: 24.713063298177318\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('development.csv', sep=',')\n",
    "y = df[['x','y']].values\n",
    "df.drop(columns=['x','y'], inplace=True)\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA()\n",
    "pca_df = pca.fit_transform(df.values)\n",
    "mdf = np.sum(np.cumsum(pca.explained_variance_ratio_) < .90) + 1\n",
    "pca_m = PCA(n_components=mdf)\n",
    "pca_df = pca_m.fit_transform(df.values)\n",
    "#X_train = pca_df\n",
    "#y_train = y\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(pca_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.where(np.isinf(X_train), np.finfo(np.float32).max, X_train)\n",
    "from sklearn.neighbors import KNeighborsRegressor #183.341\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "reg = KNeighborsRegressor(n_neighbors=9 , weights='distance', algorithm='auto')\n",
    "reg.fit(X_train, y_train)                    \n",
    "y_pred = reg.predict(X_valid)\n",
    "\n",
    "print(f'Metric value: {custom_loss_func(y_valid, y_pred)}') # Metric value: 4.742701679372149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 14 features, but RandomForestRegressor is expecting 52 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/francescogiannuzzo/Desktop/DSL Proj/DSL_Winter_Project_2024/reposcore.ipynb Cella 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m reg \u001b[39m=\u001b[39m RandomForestRegressor(n_estimators \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m, criterion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msquared_error\u001b[39m\u001b[39m'\u001b[39m, max_features\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msqrt\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m reg\u001b[39m.\u001b[39mfit(X_train, y_train)                    \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m y_pred \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39;49mpredict(X_valid) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m#y = df[['x','y']].values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Crea un DataFrame di esempio con due colonne come coordinate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Crea una figura 3D\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/francescogiannuzzo/Desktop/DSL%20Proj/DSL_Winter_Project_2024/reposcore.ipynb#X33sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m6\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:984\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    982\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    983\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 984\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    986\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    987\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 626\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 14 features, but RandomForestRegressor is expecting 52 features as input."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "df = pd.read_csv('development.csv', sep=',')\n",
    "\n",
    "noise_pmax = []\n",
    "noise_negpmax = []\n",
    "noise_area = []#4.7\n",
    "noise_tmax = []\n",
    "noise_rms = []\n",
    "noise_vpp = []\n",
    "noise_slewrate = []\n",
    "pmax = [f'pmax[{i}]' for i in range(18)]\n",
    "negpmax = [f'negpmax[{i}]' for i in range(18)]\n",
    "for i in range(0,18):\n",
    "    df[f\"vpp[{i}]\"] = (df[f\"pmax[{i}]\"] - df[f\"negpmax[{i}]\"])\n",
    "df = df[df['negpmax[1]'] < 0]\n",
    "df = df[df['negpmax[2]'] < 0]\n",
    "df = df[df['negpmax[3]'] < 0]\n",
    "df = df[df['negpmax[4]'] < 0]\n",
    "df = df[df['negpmax[5]'] < 0]\n",
    "df = df[df['negpmax[6]'] < 0]\n",
    "df = df[df['negpmax[8]'] < 0]\n",
    "df = df[df['negpmax[9]'] < 0]\n",
    "df = df[df['negpmax[10]'] < 0]\n",
    "df = df[df['negpmax[11]'] < 0]\n",
    "df = df[df['negpmax[13]'] < 0]\n",
    "df = df[df['negpmax[14]'] < 0]\n",
    "df = df[df['negpmax[15]'] < 0]\n",
    "for i in [0, 7, 12, 16, 17]: \n",
    "    noise_pmax.append(f'pmax[{i}]')\n",
    "    noise_area.append(f'area[{i}]')\n",
    "    noise_area.append(f'negpmax[{i}]')\n",
    "    noise_vpp.append(f'vpp[{i}]')\n",
    "for i in range(0, 18): \n",
    "    noise_rms.append(f'rms[{i}]')\n",
    "    noise_tmax.append(f'tmax[{i}]')\n",
    "noise = noise_pmax + noise_negpmax + noise_area + noise_tmax + noise_rms+ noise_vpp + noise_slewrate\n",
    "df.drop(columns=noise, inplace=True)\n",
    "y = df[['x','y']].values\n",
    "#df.drop(columns=['x','y'], inplace=True)\n",
    "df_eval = pd.read_csv('evaluation.csv', sep=',')#4.76 con -neg\n",
    "#for i in range(0,18):\n",
    "#    condition = abs(df_eval[f\"tmax[{i}]\"]) > 1e-6\n",
    "#    df_eval[f\"slewrate[{i}]\"] = np.where(condition, ((df_eval[f\"pmax[{i}]\"] - df_eval[f\"negpmax[{i}]\"])) / df_eval[f\"tmax[{i}]\"], np.finfo(np.float32).max)\n",
    "for i in range(0,18):\n",
    "    df_eval[f\"vpp[{i}]\"] = (df_eval[f\"pmax[{i}]\"] - df_eval[f\"negpmax[{i}]\"])\n",
    "#for i in range(0,18):\n",
    "#    df_eval[f\"widh[{i}]\"] = df_eval[f\"area[{i}]\"]/((df_eval[f\"pmax[{i}]\"]-df_eval[f\"negpmax[{i}]\"])/2)\n",
    "#for i in range(0,18):\n",
    "#    df_eval[f\"widhRMS[{i}]\"] = df_eval[f\"rms[{i}]\"]/((df_eval[f\"pmax[{i}]\"]-df_eval[f\"negpmax[{i}]\"])/2)\n",
    "df_eval.drop(columns=noise, inplace=True)\n",
    "\n",
    "X_train = df.drop(columns=['x', 'y']).values\n",
    "y_trainX = df[['x']].values\n",
    "y_trainY = df[['y']].values\n",
    "y_train = df[['x','y']].values\n",
    "X_test = df_eval.drop(columns='Id').values\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators = 200, criterion='squared_error', max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "reg.fit(X_train, y_train)                    \n",
    "y_pred = reg.predict(X_valid) \n",
    "\n",
    "#y = df[['x','y']].values\n",
    "# Crea un DataFrame di esempio con due colonne come coordinate\n",
    "\n",
    "# Crea una figura 3D\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred[:,0], y_pred[:,1], c='r', marker='o', alpha=0.25)\n",
    "#plt.scatter(y[:,0], y[:,1], c='r', marker='o', alpha=0.25)\n",
    "# Aggiungi etichette agli as\n",
    "\n",
    "# Mostra il plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
